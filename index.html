<!doctype html><html lang=en dir=auto><head><meta name=generator content="Hugo 0.122.0"><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><script type=text/javascript src=https://www.maths.nottingham.ac.uk/plp/pmadw/LaTeXMathML.js></script><meta name=robots content="index, follow"><title>KiloBytes by KB</title>
<meta name=description content><meta name=author content><link rel=canonical href=https://Kshitij-Banerjee.github.io/><link crossorigin=anonymous href=/assets/css/stylesheet.4cb5d59298692facab5b270399a4560592b36cb58936d3c922114e90da87e031.css integrity="sha256-TLXVkphpL6yrWycDmaRWBZKzbLWJNtPJIhFOkNqH4DE=" rel="preload stylesheet" as=style><link rel=icon href=https://Kshitij-Banerjee.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://Kshitij-Banerjee.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://Kshitij-Banerjee.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://Kshitij-Banerjee.github.io/apple-touch-icon.png><link rel=mask-icon href=https://Kshitij-Banerjee.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate type=application/rss+xml href=https://Kshitij-Banerjee.github.io/index.xml><noscript><style>#theme-toggle,.top-link{display:none}</style></noscript><meta name=author content="Kshitij Banerjee"><meta name=description content="Kshitij Banerjee's notes..."><script type=application/ld+json>{"@context":"https://schema.org","@type":"Person","name":"Kshitij Banerjee","url":"https://kshitij-banerjee.github.io/"}</script><meta property="og:title" content="KiloBytes by KB"><meta property="og:description" content><meta property="og:type" content="website"><meta property="og:url" content="https://Kshitij-Banerjee.github.io/"><meta name=twitter:card content="summary"><meta name=twitter:title content="KiloBytes by KB"><meta name=twitter:description content><script type=application/ld+json>{"@context":"https://schema.org","@type":"Organization","name":"KiloBytes by KB","url":"https://Kshitij-Banerjee.github.io","description":"","thumbnailUrl":"https://Kshitij-Banerjee.github.io/favicon.ico","sameAs":[]}</script></head><body class=list id=top><header class=header><nav class=nav><div class=logo><a href=https://Kshitij-Banerjee.github.io accesskey=h title="KiloBytes by KB (Alt + H)">KiloBytes by KB</a><div class=logo-switches></div></div><ul id=menu></ul></nav></header><main class=main><article class=first-entry><figure class=entry-cover><img loading=lazy src=https://Kshitij-Banerjee.github.io/GPT-3_banner.png alt></figure><header class=entry-header><h2>Understanding GPT 1, 2 and 3</h2></header><div class=entry-content><p>Introduction The goal of this series of posts, is to form foundational knowledge that helps us understanding modern state-of-the-art LLM models, and gain a comprehensive understanding of GPT via reading the seminal papers themselves.
In my previous post, I covered transformers via the original paper “Attention is all you need” that brought the innovation that made all this progress possible.
This post will focus on GPT-3 and its predecessors GPT-1 and 2....</p></div><footer class=entry-footer>&lt;span title='2023-10-01 00:00:00 +0000 UTC'>October 1, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Understanding GPT 1, 2 and 3" href=https://Kshitij-Banerjee.github.io/2023/10/01/understanding-gpt-1-2-and-3/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://Kshitij-Banerjee.github.io/Transformers_banner_1689490231707_0.png alt></figure><header class=entry-header><h2>Understanding GPT - Transformers</h2></header><div class=entry-content><p>Introduction The goal of this series of posts, is to form foundational knowledge that helps us understanding modern state-of-the-art LLM models, and gain a comprehensive understanding of GPT via reading the seminal papers themselves.
In my previous post, I covered some of the seminal papers that formulated sequence based models from RNNs to the Attention mechanism in encoder-decoder architectures. If you don’t know about them, or would like a quick refresher - I recommend reading through the previous post before continuing here....</p></div><footer class=entry-footer>&lt;span title='2023-07-07 00:00:00 +0000 UTC'>July 7, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Understanding GPT - Transformers" href=https://Kshitij-Banerjee.github.io/2023/07/07/understanding-gpt-transformers/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://Kshitij-Banerjee.github.io/UnderstandingGPTBanner.jpg alt></figure><header class=entry-header><h2>Understanding GPT - A Journey from RNNs to Attention</h2></header><div class=entry-content><p>Introduction ChatGPT has rightly taken the world by storm, and has possibly started the 6th wave. Given its importance, the rush to build new products and research on top is understandable. But, I’ve always liked to ground myself with foundational knowledge on how things work, before exploring anything additive. To gain such foundational knowledge, I believe understanding the progression of techniques and models is crucial to comprehend how these LLM models work under the hood....</p></div><footer class=entry-footer>&lt;span title='2023-06-18 00:00:00 +0000 UTC'>June 18, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Understanding GPT - A Journey from RNNs to Attention" href=https://Kshitij-Banerjee.github.io/2023/06/18/understanding-gpt-a-journey-from-rnns-to-attention/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://Kshitij-Banerjee.github.io/image_1676730500910_0.png alt></figure><header class=entry-header><h2>Loss Functions in ML</h2></header><div class=entry-content><p>Introduction Loss functions tell the algorithm how far we are from actual truth, and their gradients/derivates help understand how to reduce the overall loss (by changing the parameters being trained on)
All losses in keras defined here
Frequently we see the loss function being expressed as a negative loss, why is that so? Plot: As probabilities only lie between [0-1], the plot is only relevant between X from 0-1
This means, that it penalises a low probability of success exponentially more....</p></div><footer class=entry-footer>&lt;span title='2023-02-18 00:00:00 +0000 UTC'>February 18, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Loss Functions in ML" href=https://Kshitij-Banerjee.github.io/2023/02/18/loss-functions-in-ml/></a></article><article class=post-entry><header class=entry-header><h2>Intro to ML</h2></header><div class=entry-content><p>Introduction Note: These are my rough notes, which are auto-synced from my private LogSeq, and is a WIP.
I’ll update and make these more readable in the future (which possibly means never :D)
Lecture Notes: https://cs229.stanford.edu/notes2022fall/main_notes.pdf Notations A pair (x^{(i)}, y^{(i)}) is called a training example, the superscript “(i)” in the notation is simply an index into the training set, and has nothing to do with exponentiation.
The notation “a := b” to denote an assignment operation...</p></div><footer class=entry-footer>&lt;span title='2023-01-20 00:00:00 +0000 UTC'>January 20, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Intro to ML" href=https://Kshitij-Banerjee.github.io/2023/01/20/intro-to-ml/></a></article><article class=post-entry><header class=entry-header><h2>Python Cheet Sheet</h2></header><div class=entry-content><p>A quick cheatsheet on python operations
Slice:
astring = "Hello World" print(astring[3:7]) # prints-> lo w print(astring[0:10:2]) # skips one character, prints -> Hlowr print(astring[::-1]) # reverse a string using step -1 Case
astring.upper() astring.lower() Slicing complete list performs a copy
spam_copy = spam[:] Zip to loop
furniture = ['table', 'chair', 'rack', 'shelf'] price = [100, 50, 80, 40] for item, amount in zip(furniture, price): print(f'The {item} costs ${amount}') Multiple assignments...</p></div><footer class=entry-footer>&lt;span title='2023-01-02 00:00:00 +0000 UTC'>January 2, 2023&lt;/span></footer><a class=entry-link aria-label="post link to Python Cheet Sheet" href=https://Kshitij-Banerjee.github.io/2023/01/02/python-cheet-sheet/></a></article><article class=post-entry><figure class=entry-cover><img loading=lazy src=https://Kshitij-Banerjee.github.io/2022-12-26-08-10-03.jpeg alt></figure><header class=entry-header><h2>Book Summary - Grit by Angela Duckworth</h2></header><div class=entry-content><p>Book Summary - Grit by Angela Duckworth The post is a book summary of the main bullet points from the book “Grit” by “Angela Duckworth”
Components of Grit Angela breaks down grit in the following components:-
Interest: I love what I do
Practice: I will do what it takes to improve and become world-class
Purpose: What I do is important for everyone
Hope: I will keep going even when it’s difficult...</p></div><footer class=entry-footer>&lt;span title='2022-12-12 00:00:00 +0000 UTC'>December 12, 2022&lt;/span></footer><a class=entry-link aria-label="post link to Book Summary - Grit by Angela Duckworth" href=https://Kshitij-Banerjee.github.io/2022/12/12/book-summary-grit-by-angela-duckworth/></a></article><article class=post-entry><header class=entry-header><h2>Largest Area Under a Histogram (and related concepts/problems).</h2></header><div class=entry-content><p>Problem Statement: GfG quoted: Find the largest rectangular area possible in a given histogram where the largest rectangle can be made of a number of contiguous bars. For simplicity, assume that all bars have same width and the width is 1 unit. The Clever Solution Sometimes, the nicest solutions come from clues we receive from the worst ones.
What’s the naive solution ? Iterate through all possible rectangles and calculate the area....</p></div><footer class=entry-footer>&lt;span title='2017-01-30 00:00:00 +0000 UTC'>January 30, 2017&lt;/span>&amp;nbsp;·&amp;nbsp;Kshitij Banerjee</footer><a class=entry-link aria-label="post link to Largest Area Under a Histogram (and related concepts/problems)." href=https://Kshitij-Banerjee.github.io/2017/01/30/largest-area-under-a-histogram-and-related-concepts/problems./></a></article><article class=post-entry><header class=entry-header><h2>Reverse Engineer data from raw database files.</h2></header><div class=entry-content><p>How to recover data from raw .tokudb files. Why? Recently my tokudb database went corrupt after a bad shutdown and a lot of data was now lost. After a lot of googling, asking on forums check here, here and panicking in general, I finally figured out how to get my data back after some Hard core. Brute force. Raw file Reverse-Engineering. How? Step 1 : Find your raw data files. The tokufiles have an extension of ....</p></div><footer class=entry-footer>Kshitij Banerjee</footer><a class=entry-link aria-label="post link to Reverse Engineer data from raw database files. " href=https://Kshitij-Banerjee.github.io/1/01/01/reverse-engineer-data-from-raw-database-files./></a></article></main><footer class=footer><span>&copy; 2024 <a href=https://Kshitij-Banerjee.github.io>KiloBytes by KB</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script></body></html>